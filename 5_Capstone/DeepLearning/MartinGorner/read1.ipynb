{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mydata/train-images-idx3-ubyte.mnist\n",
      "Loading mydata/train-labels-idx1-ubyte.mnist\n",
      "Loading mydata/t10k-images-idx3-ubyte.mnist\n",
      "Loading mydata/t10k-labels-idx1-ubyte.mnist\n"
     ]
    }
   ],
   "source": [
    "import mnist_data\n",
    "import tensorflow as tf\n",
    "import tensorflowvisu\n",
    "import math\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "mnist = mnist_data.read_data_sets(\"mydata\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "pkeep = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnist_data.DataSet"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_nn_model():\n",
    "    # three convolutional layers with their channel counts, and a\n",
    "    # fully connected layer (tha last layer has 10 softmax neurons)\n",
    "    K = 6  # first convolutional layer output depth\n",
    "    L = 12  # second convolutional layer output depth\n",
    "    M = 24  # third convolutional layer\n",
    "    N = 200  # fully connected layer\n",
    "\n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1))  # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]))\n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1))\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]))\n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1))\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]))\n",
    "\n",
    "    W4 = tf.Variable(tf.truncated_normal([7 * 7 * M, N], stddev=0.1))\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]))\n",
    "    W5 = tf.Variable(tf.truncated_normal([N, 10], stddev=0.1))\n",
    "    B5 = tf.Variable(tf.constant(0.1, tf.float32, [10]))\n",
    "\n",
    "    # The model\n",
    "    stride = 1  # output is 28x28\n",
    "    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "    stride = 2  # output is 14x14\n",
    "    Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "    stride = 2  # output is 7x7\n",
    "    Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    YY = tf.reshape(Y3, shape=[-1, 7 * 7 * M])\n",
    "\n",
    "    Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "    YY4 = tf.nn.dropout(Y4, pkeep)\n",
    "    Ylogits = tf.matmul(YY4, W5) + B5\n",
    "\n",
    "    return Ylogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions  = create_nn_model()\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predictions, Y_))*100\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo  = mnist.test.images\n",
    "foo0 = foo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(foo0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#http://feltes.ch/index.php/2015/09/20/mnist-handwritten-digits-database-decoding-with-python/\n",
    "def read_images(images_name):\n",
    "    #returns an array of flattened images\n",
    "    f = open(images_name, \"rb\")\n",
    "    ds_images = []\n",
    "    #Let's read the head of the file encoded in 32-bit integers in big-endian(4 bytes)\n",
    "    mw_32bit = f.read(4)        #magic word\n",
    "    n_numbers_32bit = f.read(4) #number of images\n",
    "    n_rows_32bit = f.read(4)    #number of rows of each image\n",
    "    n_columns_32bit = f.read(4) #number of columns of each image\n",
    "    \n",
    "    #convert it to integers ; '>i' for big endian encoding\n",
    "    mw =  struct.unpack('>i',mw_32bit)[0] \n",
    "    n_numbers = struct.unpack('>i',n_numbers_32bit)[0] \n",
    "    n_rows = struct.unpack('>i',n_rows_32bit)[0]\n",
    "    n_columns = struct.unpack('>i',n_columns_32bit)[0]\n",
    "    \n",
    "    try:\n",
    "        for i in range(n_numbers):\n",
    "            image = []\n",
    "            for r in range(n_rows):\n",
    "                for l in range(n_columns):\n",
    "                    byte = f.read(1)\n",
    "                    pixel = struct.unpack('B',byte[0])[0]\n",
    "                    image.append(pixel)            \n",
    "            ds_images.append(image)\n",
    "        \n",
    "    finally:\n",
    "        f.close()\n",
    "    return ds_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_labels(labels_name):\n",
    "    #returns an array of labels\n",
    "    f = open(labels_name, \"rb\")\n",
    "    ds_labels = []\n",
    "    #Let's read the head of the file encoded in 32-bit integers in big-endian(4 bytes)\n",
    "    mw_32bit = f.read(4)        #magic word\n",
    "    n_numbers_32bit = f.read(4) #number of labels\n",
    "    \n",
    "    #convert it to integers ; '>i' for big endian encoding\n",
    "    mw =  struct.unpack('>i',mw_32bit)[0] \n",
    "    n_numbers = struct.unpack('>i',n_numbers_32bit)[0] \n",
    "    \n",
    "    try:\n",
    "        for i in range(n_numbers):\n",
    "            byte = f.read(1)\n",
    "            label = struct.unpack('B',byte[0])[0]      \n",
    "            ds_labels.append(label)\n",
    "        \n",
    "    finally:\n",
    "        f.close()\n",
    "    return ds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "import pylab\n",
    "def read_dataset(images_name,labels_name):\n",
    "    #reads an image-file and a labels file, and returns an array of tuples of\n",
    "    #(flattened_image, label)\n",
    "    images = read_images(images_name)\n",
    "    labels = read_labels(labels_name)\n",
    "    assert len(images) == len(labels)\n",
    "    return zip(images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testset = read_dataset(\"mydata/t10k-images-idx3-ubyte.mnist\",\"mydata/t10k-labels-idx1-ubyte.mnist\")\n",
    "#read_images(\"t10k-images.idx3-ubyte\")\n",
    "#trainingset = read_dataset(\"train-images.idx3-ubyte\",\"train-labels.idx1-ubyte\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,20))\n",
    "for i in range(50):\n",
    "    sp = fig.add_subplot(10,5,i+1)\n",
    "    sp.set_title(dataset[i][1])\n",
    "    plt.axis('off')\n",
    "    image = numpy.array(dataset[i][0]).reshape(28,28)\n",
    "    plt.imshow(image,interpolation='none',cmap=pylab.gray(),label=dataset[i][1])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
