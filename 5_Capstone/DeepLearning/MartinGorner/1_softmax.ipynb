{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import mnist_data\n",
    "import tensorflowvisu\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/train-images-idx3-ubyte.mnist\n",
      "Loading data/train-labels-idx1-ubyte.mnist\n",
      "Loading data/t10k-images-idx3-ubyte.mnist\n",
      "Loading data/t10k-labels-idx1-ubyte.mnist\n"
     ]
    }
   ],
   "source": [
    "mnist = mnist_data.read_data_sets(\"data\") #data is the folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Examples: 60000\n",
      "Testing  Examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print 'Training Examples:', mnist.train.images.shape[0]\n",
    "print 'Testing  Examples:', mnist.test.images.shape[0]\n",
    "\n",
    "#mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10]) # correct answers \n",
    "\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10])) # weights W[784, 10] t.random_normal instead of tf.zeroes?\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# flatten the images into a single line of pixels\n",
    "# -1 in the shape definition means \"the only possible dimension that will preserve the number of elements\"\n",
    "XX = tf.reshape(X, [-1, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model\n",
    "Y = tf.nn.softmax(tf.matmul(XX, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss function: cross-entropy = - sum( Y_i * log(Yi) )\n",
    "#                           Y: the computed output vector\n",
    "#                           Y_: the desired output vector\n",
    "\n",
    "# cross-entropy\n",
    "# log takes the log of each element, * multiplies the tensors element by element\n",
    "# reduce_mean will add all the components in the tensor\n",
    "# so here we end up with the total cross-entropy for all images in the batch\n",
    "cross_entropy = -tf.reduce_mean(Y_ * tf.log(Y)) * 1000.0  # normalized for batches of 100 images,\n",
    "                                                          # *10 because  \"mean\" included an unwanted division by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training, learning rate = 0.005\n",
    "train_step = tf.train.GradientDescentOptimizer(0.005).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# matplotlib visualisation\n",
    "allweights = tf.reshape(W, [-1])\n",
    "allbiases = tf.reshape(b, [-1])\n",
    "I = tensorflowvisu.tf_format_mnist_images(X, Y, Y_)  # assembles 10x10 images by default\n",
    "It = tensorflowvisu.tf_format_mnist_images(X, Y, Y_, 1000, lines=25)  # 1000 images on 25 lines\n",
    "datavis = tensorflowvisu.MnistDataVis()\n",
    "\n",
    "# init\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_step(i, update_test_data, update_train_data):\n",
    "\n",
    "    # training on batches of 100 images with 100 labels\n",
    "    batch_X, batch_Y = mnist.train.next_batch(100)\n",
    "\n",
    "    # compute training values for visualisation\n",
    "    if update_train_data:\n",
    "        a, c, im, w, b = sess.run([accuracy, cross_entropy, I, allweights, allbiases], feed_dict={X: batch_X, Y_: batch_Y})\n",
    "        datavis.append_training_curves_data(i, a, c)\n",
    "        datavis.append_data_histograms(i, w, b)\n",
    "        datavis.update_image1(im)\n",
    "        print(str(i) + \": accuracy:\" + str(a) + \" loss: \" + str(c))\n",
    "\n",
    "    # compute test values for visualisation\n",
    "    if update_test_data:\n",
    "        a, c, im = sess.run([accuracy, cross_entropy, It], feed_dict={X: mnist.test.images, Y_: mnist.test.labels})\n",
    "        datavis.append_test_curves_data(i, a, c)\n",
    "        datavis.update_image2(im)\n",
    "        print(str(i) + \": ********* epoch \" + str(i*100//mnist.train.images.shape[0]+1) + \" ********* test accuracy:\" + str(a) + \" test loss: \" + str(c))\n",
    "\n",
    "    # the backpropagation training step\n",
    "    sess.run(train_step, feed_dict={X: batch_X, Y_: batch_Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: accuracy:0.13 loss: 230.259\n",
      "0: ********* epoch 1 ********* test accuracy:0.098 test loss: 230.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.py:2437: MatplotlibDeprecationWarning: Using default event loop until function specific to this GUI is implemented\n",
      "  warnings.warn(str, mplDeprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: accuracy:0.6 loss: 115.933\n",
      "10: ********* epoch 1 ********* test accuracy:0.6787 test loss: 104.211\n",
      "20: accuracy:0.83 loss: 61.2917\n",
      "20: ********* epoch 1 ********* test accuracy:0.8488 test loss: 59.6142\n",
      "30: accuracy:0.81 loss: 63.7258\n",
      "30: ********* epoch 1 ********* test accuracy:0.8639 test loss: 52.2593\n",
      "40: accuracy:0.88 loss: 45.9763\n",
      "40: ********* epoch 1 ********* test accuracy:0.8704 test loss: 48.1346\n",
      "50: accuracy:0.88 loss: 46.4928\n",
      "50: ********* epoch 1 ********* test accuracy:0.8728 test loss: 46.7755\n",
      "60: accuracy:0.95 loss: 28.2206\n",
      "70: accuracy:0.86 loss: 53.9742\n",
      "80: accuracy:0.89 loss: 31.6543\n",
      "90: accuracy:0.92 loss: 31.7568\n",
      "100: accuracy:0.91 loss: 38.8968\n",
      "100: ********* epoch 1 ********* test accuracy:0.8812 test loss: 41.3588\n",
      "110: accuracy:0.93 loss: 26.7649\n",
      "120: accuracy:0.88 loss: 36.2421\n",
      "130: accuracy:0.76 loss: 69.8536\n",
      "140: accuracy:0.85 loss: 46.7728\n",
      "150: accuracy:0.95 loss: 25.0937\n",
      "150: ********* epoch 1 ********* test accuracy:0.8992 test loss: 35.9475\n",
      "160: accuracy:0.86 loss: 45.4608\n",
      "170: accuracy:0.88 loss: 41.904\n",
      "180: accuracy:0.91 loss: 31.7978\n",
      "190: accuracy:0.9 loss: 38.7093\n",
      "200: accuracy:0.85 loss: 48.913\n",
      "200: ********* epoch 1 ********* test accuracy:0.889 test loss: 38.1964\n",
      "210: accuracy:0.9 loss: 41.688\n",
      "220: accuracy:0.96 loss: 20.8624\n",
      "230: accuracy:0.86 loss: 44.4859\n",
      "240: accuracy:0.89 loss: 34.0795\n",
      "250: accuracy:0.93 loss: 27.7307\n",
      "250: ********* epoch 1 ********* test accuracy:0.9062 test loss: 33.8948\n",
      "260: accuracy:0.92 loss: 23.7444\n",
      "270: accuracy:0.94 loss: 21.158\n",
      "280: accuracy:0.94 loss: 17.8428\n",
      "290: accuracy:0.92 loss: 31.8188\n",
      "300: accuracy:0.86 loss: 38.3629\n",
      "300: ********* epoch 1 ********* test accuracy:0.9033 test loss: 33.9622\n",
      "310: accuracy:0.9 loss: 36.1839\n",
      "320: accuracy:0.88 loss: 35.3898\n",
      "330: accuracy:0.89 loss: 32.4993\n",
      "340: accuracy:0.94 loss: 28.0641\n",
      "350: accuracy:0.95 loss: 22.9529\n",
      "350: ********* epoch 1 ********* test accuracy:0.9103 test loss: 32.0112\n",
      "360: accuracy:0.89 loss: 39.085\n",
      "370: accuracy:0.87 loss: 37.8754\n",
      "380: accuracy:0.9 loss: 33.1825\n",
      "390: accuracy:0.96 loss: 21.6576\n",
      "400: accuracy:0.91 loss: 30.2491\n",
      "400: ********* epoch 1 ********* test accuracy:0.9078 test loss: 32.4859\n",
      "410: accuracy:0.91 loss: 37.0134\n",
      "420: accuracy:0.9 loss: 37.4915\n",
      "430: accuracy:0.87 loss: 35.3088\n",
      "440: accuracy:0.9 loss: 22.9389\n",
      "450: accuracy:0.88 loss: 54.3214\n",
      "450: ********* epoch 1 ********* test accuracy:0.9042 test loss: 33.0118\n",
      "460: accuracy:0.87 loss: 46.0602\n",
      "470: accuracy:0.91 loss: 28.0676\n",
      "480: accuracy:0.95 loss: 26.3964\n",
      "490: accuracy:0.86 loss: 59.2094\n",
      "500: accuracy:0.9 loss: 36.8728\n",
      "500: ********* epoch 1 ********* test accuracy:0.908 test loss: 31.6427\n",
      "510: accuracy:0.93 loss: 18.8119\n",
      "520: accuracy:0.88 loss: 39.8153\n",
      "530: accuracy:0.9 loss: 28.6548\n",
      "540: accuracy:0.87 loss: 43.0495\n",
      "550: accuracy:0.92 loss: 27.2743\n",
      "550: ********* epoch 1 ********* test accuracy:0.9103 test loss: 31.7978\n",
      "560: accuracy:0.94 loss: 23.4968\n",
      "570: accuracy:0.95 loss: 31.7241\n",
      "580: accuracy:0.92 loss: 23.519\n",
      "590: accuracy:0.98 loss: 8.55144\n",
      "600: accuracy:0.88 loss: 38.6686\n",
      "600: ********* epoch 2 ********* test accuracy:0.9053 test loss: 32.3965\n",
      "610: accuracy:0.94 loss: 23.1706\n",
      "620: accuracy:0.9 loss: 35.5548\n",
      "630: accuracy:0.85 loss: 58.8127\n",
      "640: accuracy:0.87 loss: 39.1411\n",
      "650: accuracy:0.87 loss: 44.9261\n",
      "650: ********* epoch 2 ********* test accuracy:0.9079 test loss: 31.3055\n",
      "660: accuracy:0.92 loss: 27.7819\n",
      "670: accuracy:0.91 loss: 34.7386\n",
      "680: accuracy:0.84 loss: 49.5855\n",
      "690: accuracy:0.91 loss: 31.6132\n",
      "700: accuracy:0.91 loss: 37.1303\n",
      "700: ********* epoch 2 ********* test accuracy:0.916 test loss: 30.3445\n",
      "710: accuracy:0.9 loss: 34.9189\n",
      "720: accuracy:0.89 loss: 40.9104\n",
      "730: accuracy:0.89 loss: 32.619\n",
      "740: accuracy:0.9 loss: 34.4026\n",
      "750: accuracy:0.92 loss: 25.3127\n",
      "750: ********* epoch 2 ********* test accuracy:0.9209 test loss: 29.0536\n",
      "760: accuracy:0.91 loss: 27.6629\n",
      "770: accuracy:0.92 loss: 27.2203\n",
      "780: accuracy:0.91 loss: 32.1441\n",
      "790: accuracy:0.91 loss: 29.5681\n",
      "800: accuracy:0.89 loss: 37.0801\n",
      "800: ********* epoch 2 ********* test accuracy:0.9147 test loss: 30.0724\n",
      "810: accuracy:0.91 loss: 29.4944\n",
      "820: accuracy:0.94 loss: 37.8746\n",
      "830: accuracy:0.89 loss: 33.4896\n",
      "840: accuracy:0.91 loss: 30.5159\n",
      "850: accuracy:0.9 loss: 26.3775\n",
      "850: ********* epoch 2 ********* test accuracy:0.9174 test loss: 28.763\n",
      "860: accuracy:0.95 loss: 22.3356\n",
      "870: accuracy:0.89 loss: 35.3145\n",
      "880: accuracy:0.83 loss: 57.6458\n",
      "890: accuracy:0.92 loss: 32.2832\n",
      "900: accuracy:0.9 loss: 31.0666\n",
      "900: ********* epoch 2 ********* test accuracy:0.9175 test loss: 28.8827\n",
      "910: accuracy:0.95 loss: 17.5509\n",
      "920: accuracy:0.88 loss: 41.2571\n",
      "930: accuracy:0.93 loss: 32.1937\n",
      "940: accuracy:0.89 loss: 40.5735\n",
      "950: accuracy:0.9 loss: 30.3764\n",
      "950: ********* epoch 2 ********* test accuracy:0.9124 test loss: 29.7238\n",
      "960: accuracy:0.93 loss: 20.0223\n",
      "970: accuracy:0.93 loss: 31.0398\n",
      "980: accuracy:0.88 loss: 39.8879\n",
      "990: accuracy:0.94 loss: 24.8094\n",
      "1000: accuracy:0.88 loss: 26.7278\n",
      "1000: ********* epoch 2 ********* test accuracy:0.9188 test loss: 28.758\n",
      "1010: accuracy:0.91 loss: 30.2161\n",
      "1020: accuracy:0.89 loss: 27.5553\n",
      "1030: accuracy:0.92 loss: 22.7213\n",
      "1040: accuracy:0.92 loss: 19.5545\n",
      "1050: accuracy:0.89 loss: 27.2049\n",
      "1050: ********* epoch 2 ********* test accuracy:0.9134 test loss: 29.3118\n",
      "1060: accuracy:0.92 loss: 26.7328\n",
      "1070: accuracy:0.9 loss: 32.4011\n",
      "1080: accuracy:0.89 loss: 31.2429\n",
      "1090: accuracy:0.98 loss: 14.0232\n",
      "1100: accuracy:0.91 loss: 30.6062\n",
      "1100: ********* epoch 2 ********* test accuracy:0.9155 test loss: 29.336\n",
      "1110: accuracy:0.92 loss: 32.7586\n",
      "1120: accuracy:0.93 loss: 28.4726\n",
      "1130: accuracy:0.88 loss: 46.2196\n",
      "1140: accuracy:0.84 loss: 38.0271\n",
      "1150: accuracy:0.94 loss: 33.7369\n",
      "1150: ********* epoch 2 ********* test accuracy:0.9176 test loss: 29.38\n",
      "1160: accuracy:0.93 loss: 23.1469\n",
      "1170: accuracy:0.89 loss: 36.7556\n",
      "1180: accuracy:0.91 loss: 31.0138\n",
      "1190: accuracy:0.87 loss: 37.6119\n",
      "1200: accuracy:0.95 loss: 25.6069\n",
      "1200: ********* epoch 3 ********* test accuracy:0.9162 test loss: 29.2666\n",
      "1210: accuracy:0.95 loss: 32.312\n",
      "1220: accuracy:0.88 loss: 33.068\n",
      "1230: accuracy:0.88 loss: 43.628\n",
      "1240: accuracy:0.93 loss: 31.936\n",
      "1250: accuracy:0.93 loss: 28.3002\n",
      "1250: ********* epoch 3 ********* test accuracy:0.9198 test loss: 29.0504\n",
      "1260: accuracy:0.87 loss: 47.1314\n",
      "1270: accuracy:0.95 loss: 21.5655\n",
      "1280: accuracy:0.95 loss: 20.9565\n",
      "1290: accuracy:0.92 loss: 20.0584\n",
      "1300: accuracy:0.89 loss: 34.3578\n",
      "1300: ********* epoch 3 ********* test accuracy:0.9203 test loss: 28.8948\n",
      "1310: accuracy:0.92 loss: 31.8322\n",
      "1320: accuracy:0.91 loss: 41.2759\n",
      "1330: accuracy:0.9 loss: 27.0881\n",
      "1340: accuracy:0.97 loss: 11.5851\n",
      "1350: accuracy:0.93 loss: 30.4115\n",
      "1350: ********* epoch 3 ********* test accuracy:0.9164 test loss: 30.3628\n",
      "1360: accuracy:0.89 loss: 32.2418\n",
      "1370: accuracy:0.89 loss: 37.4151\n",
      "1380: accuracy:0.93 loss: 28.2637\n",
      "1390: accuracy:0.9 loss: 35.5819\n",
      "1400: accuracy:0.89 loss: 35.7849\n",
      "1400: ********* epoch 3 ********* test accuracy:0.9202 test loss: 28.282\n",
      "1410: accuracy:0.91 loss: 31.8386\n",
      "1420: accuracy:0.92 loss: 26.4341\n",
      "1430: accuracy:0.89 loss: 37.2882\n",
      "1440: accuracy:0.93 loss: 23.3353\n",
      "1450: accuracy:0.95 loss: 19.0202\n",
      "1450: ********* epoch 3 ********* test accuracy:0.9195 test loss: 28.1523\n",
      "1460: accuracy:0.88 loss: 31.6714\n",
      "1470: accuracy:0.89 loss: 32.2932\n",
      "1480: accuracy:0.91 loss: 22.1642\n",
      "1490: accuracy:0.91 loss: 32.5408\n",
      "1500: accuracy:0.94 loss: 31.1478\n",
      "1500: ********* epoch 3 ********* test accuracy:0.9175 test loss: 28.732\n",
      "1510: accuracy:0.94 loss: 28.0293\n",
      "1520: accuracy:0.91 loss: 25.7836\n",
      "1530: accuracy:0.91 loss: 31.1297\n",
      "1540: accuracy:0.94 loss: 24.6733\n",
      "1550: accuracy:0.93 loss: 25.2361\n",
      "1550: ********* epoch 3 ********* test accuracy:0.9188 test loss: 28.3515\n",
      "1560: accuracy:0.92 loss: 25.7261\n",
      "1570: accuracy:0.92 loss: 35.3029\n",
      "1580: accuracy:0.9 loss: 24.6823\n",
      "1590: accuracy:0.97 loss: 12.2549\n",
      "1600: accuracy:0.92 loss: 22.3409\n",
      "1600: ********* epoch 3 ********* test accuracy:0.9194 test loss: 29.4523\n",
      "1610: accuracy:0.94 loss: 23.9514\n",
      "1620: accuracy:0.96 loss: 17.3564\n",
      "1630: accuracy:0.89 loss: 29.2413\n",
      "1640: accuracy:0.9 loss: 34.7623\n",
      "1650: accuracy:0.91 loss: 35.4466\n",
      "1650: ********* epoch 3 ********* test accuracy:0.9203 test loss: 28.1104\n",
      "1660: accuracy:0.95 loss: 19.4509\n",
      "1670: accuracy:0.97 loss: 20.1116\n",
      "1680: accuracy:0.92 loss: 24.4994\n",
      "1690: accuracy:0.89 loss: 29.9784\n",
      "1700: accuracy:0.96 loss: 20.3202\n",
      "1700: ********* epoch 3 ********* test accuracy:0.9201 test loss: 28.0151\n",
      "1710: accuracy:0.94 loss: 21.96\n",
      "1720: accuracy:0.89 loss: 31.1693\n",
      "1730: accuracy:0.97 loss: 18.9362\n",
      "1740: accuracy:0.96 loss: 18.4092\n",
      "1750: accuracy:0.92 loss: 30.8588\n",
      "1750: ********* epoch 3 ********* test accuracy:0.9155 test loss: 29.0919\n",
      "1760: accuracy:0.88 loss: 40.2609\n",
      "1770: accuracy:0.93 loss: 23.0246\n",
      "1780: accuracy:0.93 loss: 18.1966\n",
      "1790: accuracy:0.93 loss: 23.1512\n",
      "1800: accuracy:0.9 loss: 37.5809\n",
      "1800: ********* epoch 4 ********* test accuracy:0.9208 test loss: 27.7315\n",
      "1810: accuracy:0.87 loss: 39.3804\n",
      "1820: accuracy:0.91 loss: 49.0247\n",
      "1830: accuracy:0.94 loss: 26.8298\n",
      "1840: accuracy:0.93 loss: 21.7122\n",
      "1850: accuracy:0.91 loss: 30.7364\n",
      "1850: ********* epoch 4 ********* test accuracy:0.9208 test loss: 28.1757\n",
      "1860: accuracy:0.89 loss: 33.3422\n",
      "1870: accuracy:0.94 loss: 21.2185\n",
      "1880: accuracy:0.9 loss: 27.7519\n",
      "1890: accuracy:0.88 loss: 41.7945\n",
      "1900: accuracy:0.88 loss: 45.5661\n",
      "1900: ********* epoch 4 ********* test accuracy:0.9231 test loss: 27.7239\n",
      "1910: accuracy:0.92 loss: 36.7498\n",
      "1920: accuracy:0.95 loss: 19.4881\n",
      "1930: accuracy:0.86 loss: 48.6728\n",
      "1940: accuracy:0.94 loss: 23.5299\n",
      "1950: accuracy:0.93 loss: 25.5329\n",
      "1950: ********* epoch 4 ********* test accuracy:0.9173 test loss: 28.2996\n",
      "1960: accuracy:0.92 loss: 30.2808\n",
      "1970: accuracy:0.94 loss: 26.7396\n",
      "1980: accuracy:0.9 loss: 26.34\n",
      "1990: accuracy:0.88 loss: 32.8133\n",
      "2001: accuracy:0.92 loss: 31.0148\n",
      "2001: ********* epoch 4 ********* test accuracy:0.9204 test loss: 28.2532\n",
      "max test accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "datavis.animate(training_step, iterations=2000+1, train_data_update_freq=10, test_data_update_freq=50, more_tests_at_start=True)\n",
    "\n",
    "# to save the animation as a movie, add save_movie=True as an argument to datavis.animate\n",
    "# to disable the visualisation use the following line instead of the datavis.animate line\n",
    "# for i in range(2000+1): training_step(i, i % 50 == 0, i % 10 == 0)\n",
    "\n",
    "print(\"max test accuracy: \" + str(datavis.get_max_test_accuracy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
